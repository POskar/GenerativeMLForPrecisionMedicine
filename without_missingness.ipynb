{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "RANDOM_STATE = 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cardio_train.csv', delimiter=';')\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['cardio'])\n",
    "y = df['cardio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>gender</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.436062</td>\n",
       "      <td>0.443452</td>\n",
       "      <td>-0.847873</td>\n",
       "      <td>-0.122182</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307686</td>\n",
       "      <td>-1.018168</td>\n",
       "      <td>0.749831</td>\n",
       "      <td>0.072610</td>\n",
       "      <td>-0.035180</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.247997</td>\n",
       "      <td>0.078047</td>\n",
       "      <td>-0.708942</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>-0.141297</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.748152</td>\n",
       "      <td>0.565254</td>\n",
       "      <td>0.541435</td>\n",
       "      <td>0.137541</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.808543</td>\n",
       "      <td>-1.018168</td>\n",
       "      <td>-1.264666</td>\n",
       "      <td>-0.187113</td>\n",
       "      <td>-0.194356</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>-0.092762</td>\n",
       "      <td>0.443452</td>\n",
       "      <td>0.124642</td>\n",
       "      <td>-0.057251</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>1.269492</td>\n",
       "      <td>-0.774565</td>\n",
       "      <td>3.597913</td>\n",
       "      <td>0.072610</td>\n",
       "      <td>-0.035180</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>-0.163286</td>\n",
       "      <td>2.270477</td>\n",
       "      <td>2.139139</td>\n",
       "      <td>0.332333</td>\n",
       "      <td>-0.035180</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>1.200589</td>\n",
       "      <td>-0.165556</td>\n",
       "      <td>-0.153219</td>\n",
       "      <td>0.040145</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.434144</td>\n",
       "      <td>0.687055</td>\n",
       "      <td>-0.153219</td>\n",
       "      <td>-0.057251</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    height    weight     ap_hi     ap_lo  gender  cholesterol  \\\n",
       "0     -0.436062  0.443452 -0.847873 -0.122182 -0.088238       2            1   \n",
       "1      0.307686 -1.018168  0.749831  0.072610 -0.035180       1            3   \n",
       "2     -0.247997  0.078047 -0.708942  0.007679 -0.141297       1            3   \n",
       "3     -0.748152  0.565254  0.541435  0.137541  0.017879       2            1   \n",
       "4     -0.808543 -1.018168 -1.264666 -0.187113 -0.194356       1            1   \n",
       "...         ...       ...       ...       ...       ...     ...          ...   \n",
       "69995 -0.092762  0.443452  0.124642 -0.057251 -0.088238       2            1   \n",
       "69996  1.269492 -0.774565  3.597913  0.072610 -0.035180       1            2   \n",
       "69997 -0.163286  2.270477  2.139139  0.332333 -0.035180       2            3   \n",
       "69998  1.200589 -0.165556 -0.153219  0.040145 -0.088238       1            1   \n",
       "69999  0.434144  0.687055 -0.153219 -0.057251 -0.088238       1            2   \n",
       "\n",
       "       gluc  smoke  alco  active  \n",
       "0         1      0     0       1  \n",
       "1         1      0     0       1  \n",
       "2         1      0     0       0  \n",
       "3         1      0     0       1  \n",
       "4         1      0     0       0  \n",
       "...     ...    ...   ...     ...  \n",
       "69995     1      1     0       1  \n",
       "69996     2      0     0       1  \n",
       "69997     1      0     1       0  \n",
       "69998     2      0     0       0  \n",
       "69999     1      0     0       1  \n",
       "\n",
       "[70000 rows x 11 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select columns for scaling (excluding binary or categorical features)\n",
    "numeric_columns = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform your data (only for numeric columns)\n",
    "X_scaled = X.copy()\n",
    "X_scaled[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "# Apply one-hot encoding to categorical columns\n",
    "categorical_columns = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "X_encoded = pd.get_dummies(X[categorical_columns])\n",
    "\n",
    "# Concatenate scaled numeric columns with one-hot encoded categorical columns\n",
    "X_final = pd.concat([X_scaled[numeric_columns], X_encoded], axis=1)\n",
    "\n",
    "# Ensure X_final is a DataFrame\n",
    "X_final = pd.DataFrame(X_final)\n",
    "X = X_final\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>gender</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.272227e-16</td>\n",
       "      <td>1.450116e-15</td>\n",
       "      <td>-2.905105e-16</td>\n",
       "      <td>7.623108e-17</td>\n",
       "      <td>1.745905e-17</td>\n",
       "      <td>1.349571</td>\n",
       "      <td>1.366871</td>\n",
       "      <td>1.226457</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.053771</td>\n",
       "      <td>0.803729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>0.476838</td>\n",
       "      <td>0.680250</td>\n",
       "      <td>0.572270</td>\n",
       "      <td>0.283484</td>\n",
       "      <td>0.225568</td>\n",
       "      <td>0.397179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.514407e+00</td>\n",
       "      <td>-1.332014e+01</td>\n",
       "      <td>-4.460075e+00</td>\n",
       "      <td>-1.810381e+00</td>\n",
       "      <td>-8.841161e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.315341e-01</td>\n",
       "      <td>-6.527630e-01</td>\n",
       "      <td>-6.394770e-01</td>\n",
       "      <td>-5.725127e-02</td>\n",
       "      <td>-8.823850e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.489744e-02</td>\n",
       "      <td>7.804703e-02</td>\n",
       "      <td>-1.532192e-01</td>\n",
       "      <td>-5.725127e-02</td>\n",
       "      <td>-8.823850e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.531244e-01</td>\n",
       "      <td>6.870554e-01</td>\n",
       "      <td>5.414349e-01</td>\n",
       "      <td>7.261016e-02</td>\n",
       "      <td>-3.517999e-02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.720199e+00</td>\n",
       "      <td>1.043119e+01</td>\n",
       "      <td>8.738353e+00</td>\n",
       "      <td>1.031826e+02</td>\n",
       "      <td>5.785165e+01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        height        weight         ap_hi         ap_lo  \\\n",
       "count  7.000000e+04  7.000000e+04  7.000000e+04  7.000000e+04  7.000000e+04   \n",
       "mean   5.272227e-16  1.450116e-15 -2.905105e-16  7.623108e-17  1.745905e-17   \n",
       "std    1.000007e+00  1.000007e+00  1.000007e+00  1.000007e+00  1.000007e+00   \n",
       "min   -3.514407e+00 -1.332014e+01 -4.460075e+00 -1.810381e+00 -8.841161e-01   \n",
       "25%   -7.315341e-01 -6.527630e-01 -6.394770e-01 -5.725127e-02 -8.823850e-02   \n",
       "50%    9.489744e-02  7.804703e-02 -1.532192e-01 -5.725127e-02 -8.823850e-02   \n",
       "75%    7.531244e-01  6.870554e-01  5.414349e-01  7.261016e-02 -3.517999e-02   \n",
       "max    1.720199e+00  1.043119e+01  8.738353e+00  1.031826e+02  5.785165e+01   \n",
       "\n",
       "             gender   cholesterol          gluc         smoke          alco  \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000   \n",
       "mean       1.349571      1.366871      1.226457      0.088129      0.053771   \n",
       "std        0.476838      0.680250      0.572270      0.283484      0.225568   \n",
       "min        1.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "50%        1.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "75%        2.000000      2.000000      1.000000      0.000000      0.000000   \n",
       "max        2.000000      3.000000      3.000000      1.000000      1.000000   \n",
       "\n",
       "             active  \n",
       "count  70000.000000  \n",
       "mean       0.803729  \n",
       "std        0.397179  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BIC to get the optimal number of components for GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def compute_bic(X, n_components_range):\n",
    "    \"\"\"\n",
    "    Computes the Bayesian Information Criterion (BIC) for Gaussian Mixture Models with different numbers of components.\n",
    "    \n",
    "    Parameters:\n",
    "        X (array-like): Input data.\n",
    "        n_components_range (range): Range of number of components to evaluate.\n",
    "        \n",
    "    Returns:\n",
    "        list: BIC values for each number of components.\n",
    "    \"\"\"\n",
    "    bic = []  # List to store BIC values\n",
    "    for n_components in n_components_range:\n",
    "        # Create Gaussian Mixture Model with specified number of components\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=RANDOM_STATE)\n",
    "        gmm.fit(X)  # Fit the model to the data\n",
    "        bic.append(gmm.bic(X))  # Calculate BIC and add to list\n",
    "    return bic  # Return list of BIC values\n",
    "\n",
    "optimal_n_components = 26\n",
    "\n",
    "if optimal_n_components is None:\n",
    "    n_components_range = range(1, 51)  # Range of number of components to evaluate\n",
    "    bic_values = compute_bic(X, n_components_range)  # Compute BIC values\n",
    "    optimal_n_components = n_components_range[np.argmin(bic_values)]  # Determine optimal number of components\n",
    "\n",
    "    # Plotting BIC values\n",
    "    plt.plot(n_components_range, bic_values, marker='o')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('BIC Value')\n",
    "    plt.title('BIC for Gaussian Mixture Models')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianMixture(n_components=26, random_state=404)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianMixture<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.mixture.GaussianMixture.html\">?<span>Documentation for GaussianMixture</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianMixture(n_components=26, random_state=404)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianMixture(n_components=26, random_state=404)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Gaussian Mixture Model with optimal number of components\n",
    "gmm = GaussianMixture(n_components=optimal_n_components, random_state=RANDOM_STATE)\n",
    "\n",
    "# Fit the Gaussian Mixture Model to the imputed DataFrame\n",
    "gmm.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating 10 subsets with randomly removed number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 1 has missing values in: weight\n",
      "Subset 2 has missing values in: smoke\n",
      "Subset 3 has missing values in: height, weight\n",
      "Subset 4 has missing values in: age, smoke\n",
      "Subset 5 has missing values in: age, gluc, alco\n",
      "Subset 6 has missing values in: weight, ap_lo, gluc, smoke\n",
      "Subset 7 has missing values in: age, weight, ap_lo, gender\n",
      "Subset 8 has missing values in: age, gluc, alco\n",
      "Subset 9 has missing values in: height, gender, gluc, alco\n",
      "Subset 10 has missing values in: height, ap_hi, gender\n"
     ]
    }
   ],
   "source": [
    "subsets_fraction = 0.01\n",
    "\n",
    "# Function that randomly removes features and replace their values with NaN\n",
    "def remove_features(data, num_features_to_remove):\n",
    "    subset = data.sample(frac=subsets_fraction, random_state=RANDOM_STATE)\n",
    "    features_to_remove = np.random.choice(subset.columns[:-1], num_features_to_remove, replace=False)\n",
    "    subset = subset.astype(object)\n",
    "    subset.loc[:, features_to_remove] = np.nan\n",
    "    return subset\n",
    "\n",
    "subsets = []\n",
    "\n",
    "for _ in range(2):\n",
    "    subsets.append(remove_features(X, 1))\n",
    "\n",
    "for _ in range(2):\n",
    "    subsets.append(remove_features(X, 2))\n",
    "\n",
    "for _ in range(6):\n",
    "    num_features_to_remove = np.random.randint(3, min(5, len(X.columns) - 1))\n",
    "    subsets.append(remove_features(X, num_features_to_remove))\n",
    "\n",
    "for subset_index, subset in enumerate(subsets):\n",
    "    nan_columns = subset.columns[subset.isnull().all()]\n",
    "    print(f\"Subset {subset_index+1} has missing values in: {', '.join(nan_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# Creating a deep copy for further use similar for VAE\n",
    "vae_subsets = copy.deepcopy(subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional GMM imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConditionalGMM.condGMM import CondGMM\n",
    "import json\n",
    "\n",
    "number_of_samples = 100\n",
    "\n",
    "for subset in subsets:\n",
    "    index = 0\n",
    "    for row_index, row in subset.iterrows():\n",
    "        # Get indices and values of unknown and known features\n",
    "        unknown_features_indexes = [row.index.get_loc(col) for col in row.index if pd.isna(row[col])]\n",
    "        \n",
    "        # Find indices of known features\n",
    "        known_features_indexes = list(set(range(subset.shape[1])) - set(unknown_features_indexes))\n",
    "        \n",
    "        # Extract values of known features for the given row\n",
    "        known_features_values = subset.iloc[index, known_features_indexes]\n",
    "        \n",
    "        # If all features are known, continue\n",
    "        if len(unknown_features_indexes) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Initialize CondGMM\n",
    "        cGMM = CondGMM(gmm.weights_, gmm.means_, gmm.covariances_, known_features_indexes)\n",
    "        \n",
    "        # Generate samples using Conditional GMM\n",
    "        sampled_data = cGMM.rvs(known_features_values, size=number_of_samples, random_state=RANDOM_STATE)\n",
    "        \n",
    "        # Update unknown features with sampled data\n",
    "        for feature_index in range(len(unknown_features_indexes)):\n",
    "            if unknown_features_indexes[feature_index] in categorical_columns:\n",
    "                # Approximate categorical values to the nearest whole number\n",
    "                sampled_data[:, feature_index] = np.round(sampled_data[:, feature_index])\n",
    "            subset.iloc[index, unknown_features_indexes[feature_index]] = json.dumps([sampled_data[sample_index][feature_index] for sample_index in range(sampled_data.shape[0])])\n",
    "            \n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MSE for imputed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Subset 1:\n",
      "Feature height: MSE = 1.5931680256498213\n",
      "MSE for Subset 2:\n",
      "Feature smoke: MSE = 0.13755234323605026\n",
      "MSE for Subset 3:\n",
      "Feature gender: MSE = 1.3307465083507877\n",
      "Feature height: MSE = 1.2802487354787104\n",
      "MSE for Subset 4:\n",
      "Feature age: MSE = 1.2596629166744562\n",
      "Feature smoke: MSE = 0.0900889994224423\n",
      "MSE for Subset 5:\n",
      "Feature age: MSE = 1.0800861604639225\n",
      "Feature gluc: MSE = 1.651756252288043\n",
      "Feature alco: MSE = 0.058127976007216864\n",
      "MSE for Subset 6:\n",
      "Feature height: MSE = 0.9881225302713966\n",
      "Feature ap_hi: MSE = 2.935008048726963\n",
      "Feature gluc: MSE = 1.700670973953893\n",
      "Feature smoke: MSE = 0.09155933883343995\n",
      "MSE for Subset 7:\n",
      "Feature age: MSE = 1.4919109467280252\n",
      "Feature height: MSE = 1.1022474265185724\n",
      "Feature ap_hi: MSE = 2.9310921690919747\n",
      "Feature ap_lo: MSE = 1.1715889053551538\n",
      "MSE for Subset 8:\n",
      "Feature age: MSE = 1.0800861604639225\n",
      "Feature gluc: MSE = 1.651756252288043\n",
      "Feature alco: MSE = 0.058127976007216864\n",
      "MSE for Subset 9:\n",
      "Feature gender: MSE = 1.190344643160313\n",
      "Feature ap_lo: MSE = 1.9152859060528227\n",
      "Feature gluc: MSE = 1.7574149659791525\n",
      "Feature alco: MSE = 0.05509895116593467\n",
      "MSE for Subset 10:\n",
      "Feature gender: MSE = 1.4732417270791993\n",
      "Feature weight: MSE = 0.010283816526907543\n",
      "Feature ap_lo: MSE = 1.1367518377589887\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define folder and file paths\n",
    "folder_path = \"results/without_missingness\"\n",
    "output_file_path = os.path.join(folder_path, \"cgmm_mse_scores.txt\")\n",
    "\n",
    "# Check if folder exists, if not, create it\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Open the file in \"append\" mode and create if it doesn't exist\n",
    "with open(output_file_path, \"a+\") as f:\n",
    "    f.write(f\"Results for {number_of_samples} samples with {subsets_fraction} fraction of data:\\n\")\n",
    "\n",
    "for subset_index, subset in enumerate(subsets):\n",
    "    # Determine unknown features indexes dynamically for each subset\n",
    "    unknown_features_indexes = [col_index for col_index, col in enumerate(subset.columns) if subset[col].apply(lambda x: isinstance(x, str)).any()]\n",
    "\n",
    "    if not unknown_features_indexes:\n",
    "        continue  # Skip if there are no missing values\n",
    "    \n",
    "    # Initialize dictionary to store MSE and NMSE values for each feature in the subset\n",
    "    feature_mse = {}\n",
    "    \n",
    "    # Iterate through rows in the subset DataFrame\n",
    "    for index, row in subset.iterrows():\n",
    "        # Extract original values for the current row from X\n",
    "        original_values = X.iloc[index, unknown_features_indexes].values\n",
    "        \n",
    "        # Compute MSE for each feature separately\n",
    "        for feature_index in range(len(unknown_features_indexes)):\n",
    "            # Extract generated samples for unknown features and drop NaN values\n",
    "            generated_samples_raw = json.loads(row.iloc[unknown_features_indexes].values[feature_index])\n",
    "            generated_samples = [sample for sample in generated_samples_raw if not pd.isna(sample)]\n",
    "            \n",
    "            # Extract original value for the current feature\n",
    "            original_value = original_values[feature_index]\n",
    "            \n",
    "            # Calculate variance of generated samples\n",
    "            var_generated = np.var(generated_samples)\n",
    "            \n",
    "            for sample in generated_samples:\n",
    "                if not pd.isna(sample):\n",
    "                    # Ensure both original_value and sample are arrays of the same length\n",
    "                    original_value_array = np.full_like(np.array(sample), original_value)\n",
    "                    mse_value = mean_squared_error(original_value_array.flatten(), np.array(sample).flatten())\n",
    "                    \n",
    "                    # Add MSE value to the dictionary under the corresponding feature index\n",
    "                    if unknown_features_indexes[feature_index] not in feature_mse:\n",
    "                        feature_mse[unknown_features_indexes[feature_index]] = []\n",
    "                        \n",
    "                    feature_mse[unknown_features_indexes[feature_index]].append(mse_value)\n",
    "    \n",
    "    # Print the mean squared error  for each feature and save to file\n",
    "    with open(output_file_path, \"a\") as f:\n",
    "        print(f\"MSE for Subset {subset_index + 1}:\")\n",
    "        f.write(f\"MSE for Subset {subset_index + 1}:\\n\")\n",
    "        for feature_index, mse_values in feature_mse.items():\n",
    "            mean_mse = np.mean(mse_values)\n",
    "            # mean_nmse = np.mean(feature_nmse[feature_index])\n",
    "            f.write(f'Feature {df.columns[feature_index]} MSE: {mean_mse}\\n')\n",
    "            print(f\"Feature {df.columns[feature_index]}: MSE = {mean_mse}\")\n",
    "            \n",
    "\n",
    "with open(output_file_path, \"a\") as f:\n",
    "    f.write(f\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification after cGMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each subset and convert strings to lists\n",
    "for subset in subsets:\n",
    "    for col in subset.columns:\n",
    "        subset[col] = subset[col].apply(lambda x: json.loads(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import load\n",
    "# import warnings\n",
    "\n",
    "# # Suppress all warnings related to feature names\n",
    "# warnings.filterwarnings('ignore', message=\"X does not have valid feature names\")\n",
    "\n",
    "# # Load the classifier\n",
    "# classifier = load('classifiers\\cardio_classifier.h5')\n",
    "\n",
    "# cgmm_classification_results = []\n",
    "\n",
    "# # Iterate through each subset\n",
    "# for subset_index, subset in enumerate(subsets):\n",
    "#     subset_results = []  # Initialize results for this subset\n",
    "    \n",
    "#     # Iterate over each row in the subset\n",
    "#     for row_index, row in subset.iterrows():\n",
    "#         serialized_arrays = []\n",
    "#         non_serialized_values = []\n",
    "        \n",
    "#         # Separate serialized arrays from non-serialized values\n",
    "#         for col, value in row.items():\n",
    "#             if isinstance(value, list):\n",
    "#                 serialized_arrays.append((col, value))\n",
    "#             else:\n",
    "#                 non_serialized_values.append((col, value))\n",
    "        \n",
    "#         # Initialize an empty list to store results for this row\n",
    "#         row_results = []\n",
    "        \n",
    "#         # Iterate over each index of serialized arrays\n",
    "#         for i in range(number_of_samples):\n",
    "#             # Initialize a combined row with non-serialized values\n",
    "#             combined_row = non_serialized_values.copy()\n",
    "            \n",
    "#             # Append the entry at index i of each serialized array to the combined row\n",
    "#             for col, serialized_array in serialized_arrays:\n",
    "#                 if i < len(serialized_array):\n",
    "#                     combined_row.append((col, serialized_array[i]))\n",
    "            \n",
    "#             # Convert combined_row to an array\n",
    "#             combined_row_array = [value for _, value in combined_row]\n",
    "            \n",
    "#             try:\n",
    "#                 # Run the combined row through the classifier\n",
    "#                 result_array = classifier.predict([combined_row_array])\n",
    "#                 row_results.append(result_array)\n",
    "#             except Exception as e:\n",
    "#                 # Handle any potential errors\n",
    "#                 print(f\"Error processing row {row_index}: {e}\")\n",
    "#                 row_results.append(None)\n",
    "        \n",
    "#         # Append the row results to the subset results\n",
    "#         subset_results.append(row_results)\n",
    "    \n",
    "#     # Append the subset results to the overall results\n",
    "#     cgmm_classification_results.append(subset_results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Initialize lists to store accuracy per subset\n",
    "# accuracy_per_subset = []\n",
    "\n",
    "# # Iterate through each subset and its corresponding results\n",
    "# for subset_index, subset_results in enumerate(cgmm_classification_results):\n",
    "#     true_labels = y.loc[subsets[subset_index].index]  # Get true labels for the current subset\n",
    "    \n",
    "#     # Initialize list to store predicted labels for this subset\n",
    "#     subset_predicted_labels = []\n",
    "    \n",
    "#     # Iterate through each row and its corresponding results\n",
    "#     for row_results in subset_results:\n",
    "#         # Get the predicted label for each row (assuming binary classification)\n",
    "#         predicted_label = 1 if row_results[0] > 0.5 else 0\n",
    "#         subset_predicted_labels.append(predicted_label)\n",
    "    \n",
    "#     # Calculate accuracy for this subset\n",
    "#     subset_accuracy = accuracy_score(true_labels, subset_predicted_labels)\n",
    "    \n",
    "#     # Append the accuracy for this subset to accuracy_per_subset\n",
    "#     accuracy_per_subset.append(subset_accuracy)\n",
    "\n",
    "# # Print accuracy per subset\n",
    "# for subset_index, accuracy_subset in enumerate(accuracy_per_subset):\n",
    "#     print(\"Subset\", subset_index, \"accuracy:\", accuracy_subset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1750/1750 [==============================] - 6s 2ms/step - loss: 0.2313\n",
      "Epoch 2/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0207\n",
      "Epoch 3/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0189\n",
      "Epoch 4/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0102\n",
      "Epoch 5/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0166\n",
      "Epoch 6/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0253\n",
      "Epoch 7/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0042\n",
      "Epoch 8/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0192\n",
      "Epoch 9/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0119\n",
      "Epoch 10/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0118\n",
      "Epoch 11/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0077\n",
      "Epoch 12/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0108\n",
      "Epoch 13/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0087\n",
      "Epoch 14/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0093\n",
      "Epoch 15/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0080\n",
      "Epoch 16/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0096\n",
      "Epoch 17/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0117\n",
      "Epoch 18/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0095\n",
      "Epoch 19/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0069\n",
      "Epoch 20/20\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 0.0066\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "# Define the encoder\n",
    "input_dim = X.shape[1]\n",
    "latent_dim = 10\n",
    "\n",
    "inputs = Input(shape=(input_dim,))\n",
    "encoded = Dense(64, activation='relu')(inputs)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "z_mean = Dense(latent_dim)(encoded)\n",
    "z_log_var = Dense(latent_dim)(encoded)\n",
    "\n",
    "# Reparameterization trick\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Define the decoder\n",
    "decoded = Dense(32, activation='relu')(z)\n",
    "decoded = Dense(64, activation='relu')(decoded)\n",
    "outputs = Dense(input_dim)(decoded)\n",
    "\n",
    "# Create the VAE model\n",
    "vae = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "vae.compile(optimizer='adam', loss='mse')  # Use MSE as the reconstruction loss\n",
    "\n",
    "# Train the model\n",
    "history = vae.fit(X_train, X_train, epochs=20, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 10\n",
    "\n",
    "# Iterate through each subset\n",
    "for subset_index, subset in enumerate(vae_subsets):\n",
    "    index = 0\n",
    "    # Determine unknown features indexes dynamically for each subset\n",
    "    unknown_features_indexes = np.where(subset.isnull().any())[0]\n",
    "\n",
    "    # Iterate through each row\n",
    "    for row_index, row in subset.iterrows():\n",
    "        sampled_data = np.empty((number_of_samples, len(unknown_features_indexes)))\n",
    "        # Repeat the prediction process for the specified number of samples\n",
    "        for _ in range(number_of_samples):\n",
    "            imputed_values_row = []\n",
    "            # Impute missing values for each feature index\n",
    "            for feature_index in unknown_features_indexes:\n",
    "                # Impute missing value using the VAE for the current feature and row\n",
    "                imputed_value = vae.predict(row.values.reshape(1, -1).astype(np.float32), verbose=0)[0, feature_index]\n",
    "                imputed_values_row.append(imputed_value)\n",
    "            sampled_data[_] = imputed_values_row\n",
    "        \n",
    "        for feature_index in range(len(unknown_features_indexes)):\n",
    "            if unknown_features_indexes[feature_index] in categorical_columns:\n",
    "                # Approximate categorical values to the nearest whole number\n",
    "                sampled_data[:, feature_index] = np.round(sampled_data[:, feature_index])\n",
    "            subset.iloc[index, unknown_features_indexes[feature_index]] = json.dumps([sampled_data[sample_index][feature_index] for sample_index in range(sampled_data.shape[0])])\n",
    "\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating MSE for VAE imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Subset 1:\n",
      "Feature height: MSE = 1.327385834058073\n",
      "MSE for Subset 2:\n",
      "Feature smoke: MSE = 0.213240934433591\n",
      "MSE for Subset 3:\n",
      "Feature gender: MSE = 1.4378163572569738\n",
      "Feature height: MSE = 1.3003734495152457\n",
      "MSE for Subset 4:\n",
      "Feature age: MSE = 1.150825195530349\n",
      "Feature smoke: MSE = 0.21091146399868282\n",
      "MSE for Subset 5:\n",
      "Feature age: MSE = 1.1520055093253845\n",
      "Feature gluc: MSE = 1.4563990899388597\n",
      "Feature alco: MSE = 0.08009747038850727\n",
      "MSE for Subset 6:\n",
      "Feature height: MSE = 1.3264861759008881\n",
      "Feature ap_hi: MSE = 3.315431838826927\n",
      "Feature gluc: MSE = 1.4630357201957633\n",
      "Feature smoke: MSE = 0.21238083045462372\n",
      "MSE for Subset 7:\n",
      "Feature age: MSE = 1.1568424326367113\n",
      "Feature height: MSE = 1.3283215112535052\n",
      "Feature ap_hi: MSE = 3.317003367408704\n",
      "Feature ap_lo: MSE = 2.061657052946286\n",
      "MSE for Subset 8:\n",
      "Feature age: MSE = 1.1606346838454302\n",
      "Feature gluc: MSE = 1.4571027430470982\n",
      "Feature alco: MSE = 0.08083754107069166\n",
      "MSE for Subset 9:\n",
      "Feature gender: MSE = 1.4353797169967468\n",
      "Feature ap_lo: MSE = 2.056545401683826\n",
      "Feature gluc: MSE = 1.4556341480175652\n",
      "Feature alco: MSE = 0.08208492217188652\n",
      "MSE for Subset 10:\n",
      "Feature gender: MSE = 1.4254875154644089\n",
      "Feature weight: MSE = 0.9204316586277277\n",
      "Feature ap_lo: MSE = 2.05869501054538\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "output_file_path = os.path.join(\"results/without_missingness\", \"vae_mse_scores.txt\")\n",
    "with open(output_file_path, \"a+\") as f:\n",
    "    f.write(f\"Results for {number_of_samples} samples with {subsets_fraction} fraction of data:\\n\")\n",
    "\n",
    "for subset_index, subset in enumerate(vae_subsets):\n",
    "    # Determine unknown features indexes dynamically for each subset\n",
    "    unknown_features_indexes = [col_index for col_index, col in enumerate(subset.columns) if subset[col].apply(lambda x: isinstance(x, str)).any()]\n",
    "\n",
    "    if not unknown_features_indexes:\n",
    "        continue  # Skip if there are no missing values\n",
    "    \n",
    "    # Initialize dictionary to store MSE and NMSE values for each feature in the subset\n",
    "    feature_mse = {}\n",
    "    \n",
    "    # Iterate through rows in the subset DataFrame\n",
    "    for index, row in subset.iterrows():\n",
    "        # Extract original values for the current row from X\n",
    "        original_values = X.iloc[index, unknown_features_indexes].values\n",
    "        \n",
    "        # Compute MSE for each feature separately\n",
    "        for feature_index in range(len(unknown_features_indexes)):\n",
    "            # Extract generated samples for unknown features and drop NaN values\n",
    "            generated_samples_raw = json.loads(row.iloc[unknown_features_indexes].values[feature_index])\n",
    "            generated_samples = [sample for sample in generated_samples_raw if not pd.isna(sample)]\n",
    "            \n",
    "            # Extract original value for the current feature\n",
    "            original_value = original_values[feature_index]\n",
    "            \n",
    "            # Calculate variance of generated samples\n",
    "            var_generated = np.var(generated_samples)\n",
    "            \n",
    "            for sample in generated_samples:\n",
    "                if not pd.isna(sample):\n",
    "                    # Ensure both original_value and sample are arrays of the same length\n",
    "                    original_value_array = np.full_like(np.array(sample), original_value)\n",
    "                    mse_value = mean_squared_error(original_value_array.flatten(), np.array(sample).flatten())\n",
    "                    \n",
    "                    # Add MSE value to the dictionary under the corresponding feature index\n",
    "                    if unknown_features_indexes[feature_index] not in feature_mse:\n",
    "                        feature_mse[unknown_features_indexes[feature_index]] = []\n",
    "                        \n",
    "                    feature_mse[unknown_features_indexes[feature_index]].append(mse_value)\n",
    "    \n",
    "    # Print the mean squared error  for each feature and save to file\n",
    "    with open(output_file_path, \"a\") as f:\n",
    "        print(f\"MSE for Subset {subset_index + 1}:\")\n",
    "        f.write(f\"MSE for Subset {subset_index + 1}:\\n\")\n",
    "        for feature_index, mse_values in feature_mse.items():\n",
    "            mean_mse = np.mean(mse_values)\n",
    "            f.write(f'Feature {df.columns[feature_index]} MSE: {mean_mse}\\n')\n",
    "            print(f\"Feature {df.columns[feature_index]}: MSE = {mean_mse}\")\n",
    "            \n",
    "\n",
    "with open(output_file_path, \"a\") as f:\n",
    "    f.write(f\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification after VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each subset and convert strings to lists\n",
    "for subset in vae_subsets:\n",
    "    for col in subset.columns:\n",
    "        subset[col] = subset[col].apply(lambda x: json.loads(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings related to feature names\n",
    "warnings.filterwarnings('ignore', message=\"X does not have valid feature names\")\n",
    "\n",
    "# Load the classifier\n",
    "classifier = load('classifiers\\cardio_classifier.h5')\n",
    "\n",
    "vae_classification_results = []\n",
    "\n",
    "# Iterate through each subset\n",
    "for subset_index, subset in enumerate(subsets):\n",
    "    subset_results = []  # Initialize results for this subset\n",
    "    \n",
    "    # Iterate over each row in the subset\n",
    "    for row_index, row in subset.iterrows():\n",
    "        serialized_arrays = []\n",
    "        non_serialized_values = []\n",
    "        \n",
    "        # Separate serialized arrays from non-serialized values\n",
    "        for col, value in row.items():\n",
    "            if isinstance(value, list):\n",
    "                serialized_arrays.append((col, value))\n",
    "            else:\n",
    "                non_serialized_values.append((col, value))\n",
    "        \n",
    "        # Initialize an empty list to store results for this row\n",
    "        row_results = []\n",
    "        \n",
    "        # Iterate over each index of serialized arrays\n",
    "        for i in range(number_of_samples):\n",
    "            # Initialize a combined row with non-serialized values\n",
    "            combined_row = non_serialized_values.copy()\n",
    "            \n",
    "            # Append the entry at index i of each serialized array to the combined row\n",
    "            for col, serialized_array in serialized_arrays:\n",
    "                if i < len(serialized_array):\n",
    "                    combined_row.append((col, serialized_array[i]))\n",
    "            \n",
    "            # Convert combined_row to an array\n",
    "            combined_row_array = [value for _, value in combined_row]\n",
    "            \n",
    "            try:\n",
    "                # Run the combined row through the classifier\n",
    "                result_array = classifier.predict([combined_row_array])\n",
    "                row_results.append(result_array)\n",
    "            except Exception as e:\n",
    "                # Handle any potential errors\n",
    "                print(f\"Error processing row {row_index}: {e}\")\n",
    "                row_results.append(None)\n",
    "        \n",
    "        # Append the row results to the subset results\n",
    "        subset_results.append(row_results)\n",
    "    \n",
    "    # Append the subset results to the overall results\n",
    "    vae_classification_results.append(subset_results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 0 accuracy: 0.5771428571428572\n",
      "Subset 1 accuracy: 0.6928571428571428\n",
      "Subset 2 accuracy: 0.5185714285714286\n",
      "Subset 3 accuracy: 0.5471428571428572\n",
      "Subset 4 accuracy: 0.5585714285714286\n",
      "Subset 5 accuracy: 0.5185714285714286\n",
      "Subset 6 accuracy: 0.5157142857142857\n",
      "Subset 7 accuracy: 0.5585714285714286\n",
      "Subset 8 accuracy: 0.5971428571428572\n",
      "Subset 9 accuracy: 0.5185714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize lists to store accuracy per subset\n",
    "accuracy_per_subset = []\n",
    "\n",
    "# Iterate through each subset and its corresponding results\n",
    "for subset_index, subset_results in enumerate(vae_classification_results):\n",
    "    true_labels = y.loc[subsets[subset_index].index]  # Get true labels for the current subset\n",
    "    \n",
    "    # Initialize list to store predicted labels for this subset\n",
    "    subset_predicted_labels = []\n",
    "    \n",
    "    # Iterate through each row and its corresponding results\n",
    "    for row_results in subset_results:\n",
    "        # Get the predicted label for each row (assuming binary classification)\n",
    "        predicted_label = 1 if row_results[0] > 0.5 else 0\n",
    "        subset_predicted_labels.append(predicted_label)\n",
    "    \n",
    "    # Calculate accuracy for this subset\n",
    "    subset_accuracy = accuracy_score(true_labels, subset_predicted_labels)\n",
    "    \n",
    "    # Append the accuracy for this subset to accuracy_per_subset\n",
    "    accuracy_per_subset.append(subset_accuracy)\n",
    "\n",
    "# Print accuracy per subset\n",
    "for subset_index, accuracy_subset in enumerate(accuracy_per_subset):\n",
    "    print(\"Subset\", subset_index, \"accuracy:\", accuracy_subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
