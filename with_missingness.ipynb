{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "RANDOM_STATE = 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/HAD.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'MRS_90'\n",
    "y = df.filter([target_feature])\n",
    "y.to_csv('data/HAD_target.csv', index=False)\n",
    "df = df.drop(columns=['MRS_90', 'MRS_90_DICHO'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dill import load as dill_load\n",
    "\n",
    "scalerFile = \"classifier\\scaler.pkl\"\n",
    "\n",
    "with open(scalerFile, \"rb\") as f:\n",
    "    scaler = dill_load(f)\n",
    "\n",
    "df_scaled = scaler.preprocess_clinical_data(np.asarray(df, dtype=float))\n",
    "X = pd.DataFrame(df_scaled, columns=df.columns)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating missing data based on sklearn imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the warning given while imputing missing values, 'SERUM_GLUCOSE' and 'VALV_HEART' columns are removed due to not having any other entry than '-1' value\n",
    "X = X.drop(columns=['SERUM_GLUCOSE', 'SERUM_GLUCOSE_MISSING', 'VALV_HEART'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer_df = X.copy()  # Creating a copy of the original DataFrame for imputation\n",
    "\n",
    "# Initialize IterativeImputer with median strategy for missing values\n",
    "imp = IterativeImputer(missing_values=-1, initial_strategy='mean', random_state=RANDOM_STATE)\n",
    "\n",
    "# Iterate through columns in the DataFrame\n",
    "for col in imputer_df.columns:\n",
    "    # Skip columns ending with '_MISSING'\n",
    "    if col.endswith('_MISSING'):\n",
    "        continue\n",
    "    # Check if there is a corresponding missing flag column\n",
    "    elif col + \"_MISSING\" in X.columns:\n",
    "        # Check if there are missing values to impute\n",
    "        if (imputer_df[col + \"_MISSING\"] == 1).any() and (imputer_df[col] == -1).any():\n",
    "            # Fit imputer on the column and transform the values\n",
    "            imp.fit(imputer_df[[col]])\n",
    "            imputer_df[col] = imp.transform(imputer_df[[col]]).ravel()\n",
    "            imputer_df[col + '_MISSING'] = 0\n",
    "    else:\n",
    "        # Check if there are missing values to impute\n",
    "        if (imputer_df[col] == -1).any():\n",
    "            # Fit imputer on the column and transform the values\n",
    "            imp.fit(imputer_df[[col]])\n",
    "            imputer_df[col] = imp.transform(imputer_df[[col]]).ravel()\n",
    "\n",
    "# Remove columns related to missingness flags\n",
    "imputer_df = imputer_df[imputer_df.columns.drop(list(imputer_df.filter(regex='MISSING')))]\n",
    "\n",
    "imputer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BIC to get the optimal number of components for GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def compute_bic(X, n_components_range):\n",
    "    \"\"\"\n",
    "    Computes the Bayesian Information Criterion (BIC) for Gaussian Mixture Models with different numbers of components.\n",
    "    \n",
    "    Parameters:\n",
    "        X (array-like): Input data.\n",
    "        n_components_range (range): Range of number of components to evaluate.\n",
    "        \n",
    "    Returns:\n",
    "        list: BIC values for each number of components.\n",
    "    \"\"\"\n",
    "    bic = []  # List to store BIC values\n",
    "    for n_components in n_components_range:\n",
    "        # Create Gaussian Mixture Model with specified number of components\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=RANDOM_STATE)\n",
    "        gmm.fit(X)\n",
    "        bic.append(gmm.bic(X))  # Calculate BIC and add to list\n",
    "    return bic  # Return list of BIC values\n",
    "\n",
    "optimal_n_components = None\n",
    "\n",
    "if optimal_n_components is None:\n",
    "    n_components_range = range(1, 51)  # Range of number of components to evaluate\n",
    "    bic_values = compute_bic(imputer_df, n_components_range)  # Compute BIC values\n",
    "    optimal_n_components = n_components_range[np.argmin(bic_values)]  # Determine optimal number of components\n",
    "\n",
    "    # Plotting BIC values\n",
    "    plt.plot(n_components_range, bic_values, marker='o')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('BIC Value')\n",
    "    plt.title('BIC for Gaussian Mixture Models')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gaussian Mixture Model with optimal number of components\n",
    "gmm = GaussianMixture(n_components=optimal_n_components, random_state=RANDOM_STATE)\n",
    "\n",
    "# Fit the Gaussian Mixture Model to the imputed DataFrame\n",
    "gmm.fit(imputer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Optional:* Can set all the values of a specific feature to -1 for the purpose of displaying it's distribution on the heatmap below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the values of a feature to mark them in the heatmap, e.g. CTA_CS\n",
    "heatmap_feature = 'SYS_BLOOD_PRESSURE'\n",
    "heatmap_feature_original_values = pd.Series(X[heatmap_feature].copy().values, index=X.index)\n",
    "\n",
    "# Get maximum and minimum values from the column\n",
    "heatmap_feature_max_value = X[heatmap_feature].max()\n",
    "heatmap_feature_min_value = X[heatmap_feature].min()\n",
    "\n",
    "X[heatmap_feature] = -1\n",
    "# Check if the column exists\n",
    "if heatmap_feature + '_MISSING' in X.columns:\n",
    "    X[heatmap_feature + '_MISSING'] = 1\n",
    "    \n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating samples of missing values using conditional GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConditionalGMM.condGMM import CondGMM\n",
    "import json\n",
    "\n",
    "def gmm_generate_samples(n_datapoints=2, n_samples=1000, plot_histograms=False, print_index=False):\n",
    "    \"\"\"\n",
    "    Generate samples using Conditional Gaussian Mixture Model for imputing missing data.\n",
    "\n",
    "    Args:\n",
    "        n_datapoints (int/str): Number of data points to consider\n",
    "        n_samples (int): Number of samples to generate\n",
    "        plot_histograms (bool): Whether to plot histograms of sampled data\n",
    "        print_index (bool): Whether to print the index of the current data point\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with imputed missing data\n",
    "    \"\"\"\n",
    "    if n_datapoints > X.shape[0]:\n",
    "        n_datapoints = X.shape[0]\n",
    "\n",
    "    # Create a copy of the DataFrame for data manipulation\n",
    "    temp_df = X.head(n_datapoints).copy().astype(object)\n",
    "    # Remove missing flag columns\n",
    "    temp_df = temp_df[temp_df.columns.drop(list(temp_df.filter(regex='MISSING')))]\n",
    "        \n",
    "    for index, row in X.head(n_datapoints).iterrows():\n",
    "        # Get indices and values of unknown and known features\n",
    "        unknown_features_indexes, known_features_indexes, known_features_values = get_feature_indices_and_values(temp_df, index, row)\n",
    "        \n",
    "        # If all features are known, continue\n",
    "        if len(unknown_features_indexes) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Initialize CondGMM\n",
    "        cGMM = CondGMM(gmm.weights_, gmm.means_, gmm.covariances_, known_features_indexes)\n",
    "        \n",
    "        # Generate samples using Conditional GMM\n",
    "        sampled_data = cGMM.rvs(known_features_values, size=n_samples, random_state=RANDOM_STATE)\n",
    "        \n",
    "        # Update unknown features with sampled data\n",
    "        for feature_index in range(len(unknown_features_indexes)):\n",
    "            temp_df.iloc[index, unknown_features_indexes[feature_index]] = json.dumps([sampled_data[sample_index][feature_index] for sample_index in range(n_samples)])\n",
    "\n",
    "        # Plot histograms if specified\n",
    "        if plot_histograms:\n",
    "            plot_histogram(temp_df, unknown_features_indexes, index, sampled_data)\n",
    "        \n",
    "        # Print index if specified, for debugging purposes\n",
    "        if print_index:\n",
    "            print(index)\n",
    "        \n",
    "    return temp_df\n",
    "        \n",
    "def get_feature_indices_and_values(temp_df, index, row):    \n",
    "    unknown_features_indexes = []  # Initialize list to store indices of unknown features\n",
    "    \n",
    "    # Iterate through columns in the DataFrame\n",
    "    for col in X.columns:\n",
    "        # Skip columns ending with '_MISSING'\n",
    "        if col.endswith('_MISSING'):\n",
    "            continue\n",
    "        # Check if there is a corresponding missing flag column\n",
    "        elif col + \"_MISSING\" in X.columns:\n",
    "            # Identify unknown features where missing flag is 1 and value is -1\n",
    "            if row[col + \"_MISSING\"] == 1 and (row[col] == -1):\n",
    "                unknown_features_indexes.append(temp_df.columns.get_loc(col))  # Add index of feature\n",
    "        else:\n",
    "            # Identify unknown features where value is -1\n",
    "            if (row[col] == -1):\n",
    "                unknown_features_indexes.append(temp_df.columns.get_loc(col))  # Add index of feature\n",
    "        \n",
    "    # Find indices of known features\n",
    "    known_features_indexes = list(set(range(temp_df.shape[1])) - set(unknown_features_indexes))\n",
    "    \n",
    "    # Extract values of known features for the given row\n",
    "    known_features_values = temp_df.iloc[index, known_features_indexes]\n",
    "    \n",
    "    return unknown_features_indexes, known_features_indexes, known_features_values  # Return indices and values\n",
    "\n",
    "def plot_histogram(temp_df, unknown_features_indexes, index, sampled_data, n_bins=20):\n",
    "    # Create subplots based on the number of unknown features\n",
    "    fig, axs = plt.subplots(sampled_data.shape[1], 1, figsize=(8, len(unknown_features_indexes) * 4))\n",
    "\n",
    "    # Plot histograms for each feature\n",
    "    plot_features(temp_df, sampled_data, axs, unknown_features_indexes, index, n_bins)\n",
    "\n",
    "    # Add title and labels to the figure\n",
    "    fig.suptitle(f'Histograms for index {index}', fontsize=20)  # Title with the index\n",
    "    fig.text(0.5, 0.04, 'Value', ha='center', fontsize=14)  # X-axis label\n",
    "    fig.text(0.04, 0.5, 'Frequency', va='center', rotation='vertical', fontsize=14)  # Y-axis label\n",
    "    plt.show()  # Show the figure\n",
    "\n",
    "    \n",
    "def plot_features(temp_df, sampled_data, axs, unknown_features_indexes, index, n_bins):\n",
    "    # Ensure axs is a list for consistency in cases when only one feature is plotted\n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = [axs]\n",
    "\n",
    "    for i in range(sampled_data.shape[1]):\n",
    "        expected_value = imputer_df.iloc[index, unknown_features_indexes[i]]\n",
    "        \n",
    "        # Plot histogram for the feature\n",
    "        axs[i].hist(sampled_data[:, i], bins=n_bins, alpha=0.5, label='sampled data')\n",
    "        axs[i].hist(imputer_df[imputer_df.columns[unknown_features_indexes[i]]], bins=n_bins, alpha=0.2, label='marginal data')\n",
    "        axs[i].set_title(f'{temp_df.columns[unknown_features_indexes[i]]}')\n",
    "        \n",
    "        # Add expected value as text on the histogram\n",
    "        axs[i].text(0.95, 0.95, f'Expected value: {expected_value}', ha='right', va='top', transform=axs[i].transAxes, fontsize=10, bbox=dict(facecolor='white', alpha=0.5))\n",
    "        \n",
    "        axs[i].legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "n_datapoints = X.shape[0]\n",
    "number_of_samples = 100\n",
    "cgmm_df = gmm_generate_samples(n_datapoints=n_datapoints, n_samples=number_of_samples)\n",
    "\n",
    "# Save the imputed DataFrame to a CSV file\n",
    "cgmm_df.to_csv('data/HAD_after_cgmm.csv', index=False)\n",
    "\n",
    "cgmm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MSE for generated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create output file\n",
    "output_file_path = os.path.join(\"results\", \"with_missingness.txt\")\n",
    "with open(output_file_path, \"a\") as f:\n",
    "    f.write(f\"Results for {number_of_samples} samples:\\n\")\n",
    "\n",
    "# Initialize dictionary to store MSE and NMSE values for each feature\n",
    "feature_mse = {}\n",
    "\n",
    "for index, row in cgmm_df.iterrows():\n",
    "    # Get the indices and values of unknown features\n",
    "    unknown_features_indexes = [col_index for col_index, col in enumerate(row) if isinstance(col, str)]\n",
    "    \n",
    "    # If all features are known, continue\n",
    "    if len(unknown_features_indexes) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Compare values of generated samples with imputed values\n",
    "    for feature_index in range(len(unknown_features_indexes)):\n",
    "        imputed_value = imputer_df.iloc[index, unknown_features_indexes[feature_index]]\n",
    "        sampled_value = json.loads(row.iloc[unknown_features_indexes].values[feature_index])\n",
    "        \n",
    "        for sample in sampled_value:\n",
    "            if not pd.isna(sample):\n",
    "                # Calculate mean squared error\n",
    "                mse = mean_squared_error(imputed_value.flatten(), np.array(sample).flatten())\n",
    "                \n",
    "                # Save each mse and nmse to its corresponding feature in feature_mse and feature_nmse\n",
    "                if unknown_features_indexes[feature_index] not in feature_mse:\n",
    "                    feature_mse[unknown_features_indexes[feature_index]] = []\n",
    "                \n",
    "                feature_mse[unknown_features_indexes[feature_index]].append(mse)\n",
    "        \n",
    "# Print the mean squared error and normalized mean squared error for each feature and save to file\n",
    "with open(output_file_path, \"a\") as f:\n",
    "    for feature_index, mse_list in feature_mse.items():\n",
    "        mean_mse = np.mean(mse_list)\n",
    "        f.write(f'Feature {cgmm_df.columns[feature_index]} MSE: {mean_mse}\\n')\n",
    "        print(f'Feature {cgmm_df.columns[feature_index]} MSE: {mean_mse}')\n",
    "        \n",
    "with open(output_file_path, \"a\") as f:\n",
    "    f.write(f\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Optional:* Generating heatmap which helps visualize how cGMM distributes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bin edges and adjust number of bins\n",
    "n_bins = 13\n",
    "h_min = heatmap_feature_min_value\n",
    "h_max = heatmap_feature_max_value\n",
    "width = (h_max - h_min) / (n_bins-1)\n",
    "bin_edges = np.arange(h_min - width/2, h_max +  width, width)\n",
    "\n",
    "# Save the original values of the heatmap feature\n",
    "heatmap_feature_values = cgmm_df[heatmap_feature]\n",
    "\n",
    "# Deserializing the values of the heatmap feature\n",
    "for i, entry in enumerate(heatmap_feature_values):\n",
    "    if isinstance(entry, str):\n",
    "        float_array = json.loads(entry)\n",
    "        heatmap_feature_values[i] = float_array\n",
    "\n",
    "# Determine the number of samples based on the length of an entry with a list of values\n",
    "list_length = None\n",
    "for entry in heatmap_feature_values:\n",
    "    if isinstance(entry, list):\n",
    "        list_length = len(entry)\n",
    "        break\n",
    "\n",
    "histograms = []\n",
    "\n",
    "for entry in heatmap_feature_values:\n",
    "    if isinstance(entry, list):\n",
    "        # Apply np.histogram with specified bin edges\n",
    "        hist, _ = np.histogram(entry, bins=bin_edges)\n",
    "        histograms.append(hist)\n",
    "    else:\n",
    "        # Single-value entry: Place it in the correct bin and set frequency to list_length\n",
    "        hist = np.zeros(len(bin_edges) - 1)\n",
    "        index = np.digitize([entry], bin_edges)[0] - 1\n",
    "        if 0 <= index < len(hist):\n",
    "            hist[index] = list_length\n",
    "        histograms.append(hist)\n",
    "\n",
    "# Reshape histograms to fit imshow format (histograms should be a 2D array)\n",
    "histograms_2d = np.array(histograms)\n",
    "\n",
    "# Determine figure height based on the number of datapoints\n",
    "fig_height = max(6, n_datapoints * 0.2)\n",
    "fig_width = min(max(10, bin_edges.shape[0] * 1), 32)\n",
    "\n",
    "extent = [bin_edges[0], bin_edges[-1], 0, len(histograms)]\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(fig_width, fig_height))\n",
    "plt.imshow(histograms_2d, aspect='auto', cmap='Reds', extent=extent)\n",
    "plt.colorbar()\n",
    "plt.xticks(bin_edges, labels=np.round(bin_edges, 2), rotation=90)\n",
    "plt.yticks(range(n_datapoints), range(n_datapoints))\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Index')\n",
    "plt.title(heatmap_feature + ' values heatmap generated by cGMM')\n",
    "\n",
    "# Add markers for original values of a missing feature\n",
    "original_values = heatmap_feature_original_values[heatmap_feature_original_values != -1] # Selecting only the non -1 values\n",
    "indexes = heatmap_feature_original_values.index[heatmap_feature_original_values != -1] + 0.5 # Indexes corresponding to non -1 values\n",
    "plt.scatter(original_values, indexes, color='red', marker='o', s=80, label='Original Values')\n",
    "plt.scatter(imputer_df[heatmap_feature], imputer_df.index + 0.5, color='blue', marker='x', label='Imputer Values')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('images/heatmaps/' + heatmap_feature + '_heatmap.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
