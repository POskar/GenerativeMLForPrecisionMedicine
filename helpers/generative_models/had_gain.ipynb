{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_STATE = 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGE_MISSING</th>\n",
       "      <th>SEX_F</th>\n",
       "      <th>NIHSS_BL</th>\n",
       "      <th>NIHSS_BL_MISSING</th>\n",
       "      <th>SYS_BLOOD_PRESSURE</th>\n",
       "      <th>SYS_BLOOD_PRESSURE_MISSING</th>\n",
       "      <th>PREV_MRS</th>\n",
       "      <th>PREV_MRS_MISSING</th>\n",
       "      <th>ORAL_ANTICOAGULANT</th>\n",
       "      <th>...</th>\n",
       "      <th>ONSET_TO_ADMISSION</th>\n",
       "      <th>ONSET_TO_ADMISSION_MISSING</th>\n",
       "      <th>ONSET_TO_IMAGING</th>\n",
       "      <th>ONSET_TO_IMAGING_MISSING</th>\n",
       "      <th>ONSET_TO_TPA</th>\n",
       "      <th>ONSET_TO_TPA_MISSING</th>\n",
       "      <th>ONSET_TO_GROIN</th>\n",
       "      <th>ONSET_TO_GROIN_MISSING</th>\n",
       "      <th>MRS_90</th>\n",
       "      <th>MRS_90_DICHO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  AGE_MISSING  SEX_F  NIHSS_BL  NIHSS_BL_MISSING  SYS_BLOOD_PRESSURE  \\\n",
       "0   70            0      0         3                 0                  -1   \n",
       "1   55            0      0         6                 0                 142   \n",
       "2   73            0      0         3                 0                 170   \n",
       "3   81            0      0        10                 0                  -1   \n",
       "4   81            0      1        11                 0                  -1   \n",
       "\n",
       "   SYS_BLOOD_PRESSURE_MISSING  PREV_MRS  PREV_MRS_MISSING  ORAL_ANTICOAGULANT  \\\n",
       "0                           1         0                 0                   0   \n",
       "1                           0         3                 0                   0   \n",
       "2                           0         0                 0                   1   \n",
       "3                           1         0                 0                   0   \n",
       "4                           1         0                 0                   0   \n",
       "\n",
       "   ...  ONSET_TO_ADMISSION  ONSET_TO_ADMISSION_MISSING  ONSET_TO_IMAGING  \\\n",
       "0  ...                  64                           0                96   \n",
       "1  ...                  38                           0               104   \n",
       "2  ...                  -1                           1                -1   \n",
       "3  ...                  69                           0                90   \n",
       "4  ...                  98                           0               110   \n",
       "\n",
       "   ONSET_TO_IMAGING_MISSING  ONSET_TO_TPA  ONSET_TO_TPA_MISSING  \\\n",
       "0                         0           180                     0   \n",
       "1                         0           165                     0   \n",
       "2                         1            -1                     1   \n",
       "3                         0           115                     0   \n",
       "4                         0           120                     0   \n",
       "\n",
       "   ONSET_TO_GROIN  ONSET_TO_GROIN_MISSING  MRS_90  MRS_90_DICHO  \n",
       "0              -1                       1       0             0  \n",
       "1              -1                       1       4             1  \n",
       "2              -1                       1       2             0  \n",
       "3              -1                       1       3             1  \n",
       "4              -1                       1       0             0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/HAD.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target_feature = 'MRS_90'\n",
    "y_raw = df.filter([target_feature])\n",
    "y = LabelEncoder().fit_transform(y_raw.values.ravel())\n",
    "df = df.drop(columns=['MRS_90', 'MRS_90_DICHO'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGE_MISSING</th>\n",
       "      <th>SEX_F</th>\n",
       "      <th>NIHSS_BL</th>\n",
       "      <th>NIHSS_BL_MISSING</th>\n",
       "      <th>SYS_BLOOD_PRESSURE</th>\n",
       "      <th>SYS_BLOOD_PRESSURE_MISSING</th>\n",
       "      <th>PREV_MRS</th>\n",
       "      <th>PREV_MRS_MISSING</th>\n",
       "      <th>ORAL_ANTICOAGULANT</th>\n",
       "      <th>...</th>\n",
       "      <th>CTA_CS</th>\n",
       "      <th>CTA_CS_MISSING</th>\n",
       "      <th>ONSET_TO_ADMISSION</th>\n",
       "      <th>ONSET_TO_ADMISSION_MISSING</th>\n",
       "      <th>ONSET_TO_IMAGING</th>\n",
       "      <th>ONSET_TO_IMAGING_MISSING</th>\n",
       "      <th>ONSET_TO_TPA</th>\n",
       "      <th>ONSET_TO_TPA_MISSING</th>\n",
       "      <th>ONSET_TO_GROIN</th>\n",
       "      <th>ONSET_TO_GROIN_MISSING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.362745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE  AGE_MISSING  SEX_F  NIHSS_BL  NIHSS_BL_MISSING  \\\n",
       "0  0.509804          0.0    0.0  0.071429               0.0   \n",
       "1  0.362745          0.0    0.0  0.142857               0.0   \n",
       "2  0.539216          0.0    0.0  0.071429               0.0   \n",
       "3  0.617647          0.0    0.0  0.238095               0.0   \n",
       "4  0.617647          0.0    1.0  0.261905               0.0   \n",
       "\n",
       "   SYS_BLOOD_PRESSURE  SYS_BLOOD_PRESSURE_MISSING  PREV_MRS  PREV_MRS_MISSING  \\\n",
       "0              -1.000                         1.0       0.0               0.0   \n",
       "1               0.368                         0.0       0.6               0.0   \n",
       "2               0.480                         0.0       0.0               0.0   \n",
       "3              -1.000                         1.0       0.0               0.0   \n",
       "4              -1.000                         1.0       0.0               0.0   \n",
       "\n",
       "   ORAL_ANTICOAGULANT  ...  CTA_CS  CTA_CS_MISSING  ONSET_TO_ADMISSION  \\\n",
       "0                 0.0  ...    -1.0             1.0            0.044444   \n",
       "1                 0.0  ...    -1.0             1.0            0.026389   \n",
       "2                 1.0  ...    -1.0             1.0           -1.000000   \n",
       "3                 0.0  ...    -1.0             1.0            0.047917   \n",
       "4                 0.0  ...    -1.0             1.0            0.068056   \n",
       "\n",
       "   ONSET_TO_ADMISSION_MISSING  ONSET_TO_IMAGING  ONSET_TO_IMAGING_MISSING  \\\n",
       "0                         0.0          0.066667                       0.0   \n",
       "1                         0.0          0.072222                       0.0   \n",
       "2                         1.0         -1.000000                       1.0   \n",
       "3                         0.0          0.062500                       0.0   \n",
       "4                         0.0          0.076389                       0.0   \n",
       "\n",
       "   ONSET_TO_TPA  ONSET_TO_TPA_MISSING  ONSET_TO_GROIN  ONSET_TO_GROIN_MISSING  \n",
       "0      0.125000                   0.0            -1.0                     1.0  \n",
       "1      0.114583                   0.0            -1.0                     1.0  \n",
       "2     -1.000000                   1.0            -1.0                     1.0  \n",
       "3      0.079861                   0.0            -1.0                     1.0  \n",
       "4      0.083333                   0.0            -1.0                     1.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from dill import load\n",
    "\n",
    "# Load the scaler object\n",
    "scalerFile = \"..\\predictive_models\\HAD_scaler.pkl\"\n",
    "with open(scalerFile, \"rb\") as f:\n",
    "    scaler = load(f)\n",
    "\n",
    "# Now your code should be able to load the scaler object without encountering ModuleNotFoundError for ADT\n",
    "df_scaled = scaler.preprocess_clinical_data(np.asarray(df, dtype=float))\n",
    "X = pd.DataFrame(df_scaled, columns=df.columns)\n",
    "\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning is given while imputing missing values in 'SERUM_GLUCOSE' and 'VALV_HEART' columns due to missing all values thus they are removed, only to be readded for classification\n",
    "columns_names_to_add_back_for_classification = ['SERUM_GLUCOSE', 'SERUM_GLUCOSE_MISSING', 'VALV_HEART']\n",
    "for col in list(X.filter(regex='MISSING')):\n",
    "    columns_names_to_add_back_for_classification.append(col)\n",
    "\n",
    "X = X.drop(columns=columns_names_to_add_back_for_classification, axis=1)\n",
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX_F</th>\n",
       "      <th>NIHSS_BL</th>\n",
       "      <th>SYS_BLOOD_PRESSURE</th>\n",
       "      <th>PREV_MRS</th>\n",
       "      <th>ORAL_ANTICOAGULANT</th>\n",
       "      <th>HYPERTENSION</th>\n",
       "      <th>HYPERCHOL</th>\n",
       "      <th>ISCH_HEART</th>\n",
       "      <th>SMOKING</th>\n",
       "      <th>...</th>\n",
       "      <th>OCCLUSION_M2</th>\n",
       "      <th>OCCLUSION_ICA</th>\n",
       "      <th>OCCLUSION_ACA</th>\n",
       "      <th>OCCLUSION_PCA</th>\n",
       "      <th>OCCLUSION_VB</th>\n",
       "      <th>CTA_CS</th>\n",
       "      <th>ONSET_TO_ADMISSION</th>\n",
       "      <th>ONSET_TO_IMAGING</th>\n",
       "      <th>ONSET_TO_TPA</th>\n",
       "      <th>ONSET_TO_GROIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.503282</td>\n",
       "      <td>0.452331</td>\n",
       "      <td>0.204802</td>\n",
       "      <td>-0.421110</td>\n",
       "      <td>0.135381</td>\n",
       "      <td>0.113347</td>\n",
       "      <td>0.685381</td>\n",
       "      <td>0.501059</td>\n",
       "      <td>0.304025</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276483</td>\n",
       "      <td>-0.205508</td>\n",
       "      <td>-0.389831</td>\n",
       "      <td>-0.370763</td>\n",
       "      <td>-0.380297</td>\n",
       "      <td>-0.439972</td>\n",
       "      <td>-0.294675</td>\n",
       "      <td>-0.270553</td>\n",
       "      <td>-0.648606</td>\n",
       "      <td>-0.577454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.170349</td>\n",
       "      <td>0.497986</td>\n",
       "      <td>0.296881</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.328140</td>\n",
       "      <td>0.336648</td>\n",
       "      <td>0.466887</td>\n",
       "      <td>0.504486</td>\n",
       "      <td>0.460237</td>\n",
       "      <td>0.419778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>0.748368</td>\n",
       "      <td>0.515448</td>\n",
       "      <td>0.547077</td>\n",
       "      <td>0.531583</td>\n",
       "      <td>0.734238</td>\n",
       "      <td>0.537091</td>\n",
       "      <td>0.543417</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>0.591049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.519608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.050694</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076563</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.084201</td>\n",
       "      <td>0.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.803922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.618056</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AGE       SEX_F    NIHSS_BL  SYS_BLOOD_PRESSURE    PREV_MRS  \\\n",
       "count  944.000000  944.000000  944.000000          944.000000  944.000000   \n",
       "mean     0.503282    0.452331    0.204802           -0.421110    0.135381   \n",
       "std      0.170349    0.497986    0.296881            0.693467    0.328140   \n",
       "min     -1.000000    0.000000   -1.000000           -1.000000   -1.000000   \n",
       "25%      0.421569    0.000000    0.071429           -1.000000    0.000000   \n",
       "50%      0.519608    0.000000    0.166667           -1.000000    0.000000   \n",
       "75%      0.617647    1.000000    0.404762            0.368000    0.400000   \n",
       "max      0.803922    1.000000    0.857143            0.716000    1.000000   \n",
       "\n",
       "       ORAL_ANTICOAGULANT  HYPERTENSION   HYPERCHOL  ISCH_HEART     SMOKING  \\\n",
       "count          944.000000    944.000000  944.000000  944.000000  944.000000   \n",
       "mean             0.113347      0.685381    0.501059    0.304025    0.220339   \n",
       "std              0.336648      0.466887    0.504486    0.460237    0.419778   \n",
       "min             -1.000000     -1.000000   -1.000000    0.000000   -1.000000   \n",
       "25%              0.000000      0.000000    0.000000    0.000000    0.000000   \n",
       "50%              0.000000      1.000000    1.000000    0.000000    0.000000   \n",
       "75%              0.000000      1.000000    1.000000    1.000000    0.000000   \n",
       "max              1.000000      1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "       ...  OCCLUSION_M2  OCCLUSION_ICA  OCCLUSION_ACA  OCCLUSION_PCA  \\\n",
       "count  ...    944.000000     944.000000     944.000000     944.000000   \n",
       "mean   ...     -0.276483      -0.205508      -0.389831      -0.370763   \n",
       "std    ...      0.677496       0.748368       0.515448       0.547077   \n",
       "min    ...     -1.000000      -1.000000      -1.000000      -1.000000   \n",
       "25%    ...     -1.000000      -1.000000      -1.000000      -1.000000   \n",
       "50%    ...      0.000000       0.000000       0.000000       0.000000   \n",
       "75%    ...      0.000000       0.000000       0.000000       0.000000   \n",
       "max    ...      1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       OCCLUSION_VB      CTA_CS  ONSET_TO_ADMISSION  ONSET_TO_IMAGING  \\\n",
       "count    944.000000  944.000000          944.000000        944.000000   \n",
       "mean      -0.380297   -0.439972           -0.294675         -0.270553   \n",
       "std        0.531583    0.734238            0.537091          0.543417   \n",
       "min       -1.000000   -1.000000           -1.000000         -1.000000   \n",
       "25%       -1.000000   -1.000000           -1.000000         -1.000000   \n",
       "50%        0.000000   -1.000000            0.036111          0.050694   \n",
       "75%        0.000000    0.333333            0.076563          0.097222   \n",
       "max        1.000000    1.000000            0.814583          0.893750   \n",
       "\n",
       "       ONSET_TO_TPA  ONSET_TO_GROIN  \n",
       "count    944.000000      944.000000  \n",
       "mean      -0.648606       -0.577454  \n",
       "std        0.522300        0.591049  \n",
       "min       -1.000000       -1.000000  \n",
       "25%       -1.000000       -1.000000  \n",
       "50%       -1.000000       -1.000000  \n",
       "75%        0.084201        0.104167  \n",
       "max        0.618056        0.941667  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((755, 27), (189, 27))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# This script defines the generator and discriminator models for a Generative Adversarial Imputation Network (GAIN)\n",
    "# using the Keras API in TensorFlow 2.x.\n",
    "\n",
    "def build_generator(data_dim, hidden_dim):\n",
    "    \"\"\"\n",
    "    Builds the generator model for a Generative Adversarial Imputation Network (GAIN).\n",
    "\n",
    "    Args:\n",
    "        data_dim (int): The dimensionality of the input data.\n",
    "        hidden_dim (int): The number of hidden units in the encoder and decoder.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The generator model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(data_dim,)),  # Input layer\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),  # Hidden layers\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(data_dim, activation='sigmoid')  # Output layer\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(data_dim, hidden_dim):\n",
    "    \"\"\"\n",
    "    Builds the discriminator model for a Generative Adversarial Imputation Network (GAIN).\n",
    "\n",
    "    Args:\n",
    "        data_dim (int): The dimensionality of the input data.\n",
    "        hidden_dim (int): The number of hidden units in the encoder and decoder.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The discriminator model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(data_dim,)),  # Input layer\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),  # Hidden layers\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 128)               3584      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23579 (92.11 KB)\n",
      "Trainable params: 23579 (92.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 128)               3584      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20225 (79.00 KB)\n",
      "Trainable params: 20225 (79.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup models\n",
    "data_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "\n",
    "generator = build_generator(data_dim, hidden_dim)\n",
    "discriminator = build_discriminator(data_dim, hidden_dim)\n",
    "\n",
    "# Print the model summary\n",
    "generator.summary(), discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for the discriminator\n",
    "def discriminator_loss(D_prob, M, X, G_sample):\n",
    "    D_prob = tf.cast(D_prob, dtype=tf.float32)  # Cast to float32\n",
    "    return -tf.reduce_mean(M * tf.math.log(D_prob + 1e-8) + (1 - M) * tf.math.log(1. - D_prob + 1e-8))\n",
    "\n",
    "# Loss function for the generator\n",
    "def generator_loss(D_prob, G_sample, M, X):\n",
    "    # Cast all inputs to float32 to ensure consistent data types for operations\n",
    "    D_prob = tf.cast(D_prob, dtype=tf.float32)\n",
    "    G_sample = tf.cast(G_sample, dtype=tf.float32)\n",
    "    M = tf.cast(M, dtype=tf.float32)\n",
    "    X = tf.cast(X, dtype=tf.float32)\n",
    "    \n",
    "    # Compute the binary cross-entropy loss part\n",
    "    BCE_loss = -tf.reduce_mean((1 - M) * tf.math.log(D_prob + tf.constant(1e-8, dtype=tf.float32)))\n",
    "\n",
    "    # Compute the mean squared error loss part\n",
    "    MSE_loss = tf.reduce_mean(M * tf.square(X - G_sample))\n",
    "\n",
    "    # Weighting factor for the losses\n",
    "    alpha = 0.5\n",
    "\n",
    "    # Combine the losses\n",
    "    total_loss = alpha * BCE_loss + (1 - alpha) * MSE_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# Adam optimizer is a stochastic gradient descent method\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(generator, discriminator, data, batch_size):\n",
    "    noise = tf.random.normal([batch_size, data.shape[1]])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_data = generator(noise, training=True)\n",
    "        real_output = discriminator(data, training=True)\n",
    "        fake_output = discriminator(generated_data, training=True)\n",
    "        gen_loss = generator_loss(fake_output, generated_data, data, noise)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output, data, noise)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "def train_gan(generator, discriminator, df, iterations, batch_size):\n",
    "    for iteration in range(iterations):\n",
    "        idx = np.random.choice(len(df), batch_size, replace=False)\n",
    "        data_batch = df.iloc[idx]\n",
    "        gen_loss, disc_loss = train_step(generator, discriminator, data_batch, batch_size)\n",
    "        if iteration % 1000 == 0:\n",
    "            print(f\"Iteration {iteration}, Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Generator Loss: 0.36589857935905457, Discriminator Loss: 0.7027698755264282\n",
      "Iteration 1000, Generator Loss: 3.19404935836792, Discriminator Loss: 0.012191230431199074\n",
      "Iteration 2000, Generator Loss: 4.395117282867432, Discriminator Loss: 0.0012393519282341003\n",
      "Iteration 3000, Generator Loss: 5.17070198059082, Discriminator Loss: 0.0003341997798997909\n",
      "Iteration 4000, Generator Loss: 5.684363842010498, Discriminator Loss: 0.00011812297452706844\n",
      "Iteration 5000, Generator Loss: 6.119815826416016, Discriminator Loss: 5.725143273593858e-05\n",
      "Iteration 6000, Generator Loss: 6.472872734069824, Discriminator Loss: 2.247413431177847e-05\n",
      "Iteration 7000, Generator Loss: 6.956284999847412, Discriminator Loss: 1.0969339200528339e-05\n",
      "Iteration 8000, Generator Loss: 7.046768665313721, Discriminator Loss: 5.6455382946296595e-06\n",
      "Iteration 9000, Generator Loss: 7.546322822570801, Discriminator Loss: 2.9745519896096084e-06\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "train_gan(generator, discriminator, X_train, iterations=10000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['had_gain_generator.h5']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(generator, 'had_gain_generator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
