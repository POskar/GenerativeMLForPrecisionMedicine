{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_STATE = 404"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/cardio_train.csv', delimiter=';')\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['cardio'])\n",
    "y = df['cardio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.588076</td>\n",
       "      <td>2</td>\n",
       "      <td>0.579487</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730159</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517949</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.624003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.284211</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>0.012647</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528455</td>\n",
       "      <td>2</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>0.018553</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.516918</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517949</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender    height    weight     ap_hi     ap_lo  cholesterol  \\\n",
       "0  0.588076       2  0.579487  0.273684  0.016079  0.013550            1   \n",
       "1  0.730159       1  0.517949  0.394737  0.017934  0.014453            3   \n",
       "2  0.624003       1  0.564103  0.284211  0.017316  0.012647            3   \n",
       "3  0.528455       2  0.584615  0.378947  0.018553  0.015357            1   \n",
       "4  0.516918       1  0.517949  0.242105  0.015461  0.011743            1   \n",
       "\n",
       "   gluc  smoke  alco  active  \n",
       "0     1      0     0       1  \n",
       "1     1      0     0       1  \n",
       "2     1      0     0       0  \n",
       "3     1      0     0       1  \n",
       "4     1      0     0       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Select columns to be scaled\n",
    "numeric_columns = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "categorical_columns = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "# Fit and transform your data (only for numeric columns)\n",
    "scaler = MinMaxScaler()\n",
    "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "# # Apply one-hot encoding to categorical columns\n",
    "# encoder = OneHotEncoder(sparse_output=False)  # Create the encoder\n",
    "# X_encoded = encoder.fit_transform(X[categorical_columns])  # Fit and transform the categorical data\n",
    "# column_names = encoder.get_feature_names_out(categorical_columns)  # Get new column names for encoded features\n",
    "# X_encoded = pd.DataFrame(X_encoded, columns=column_names)  # Create a DataFrame with the new column names\n",
    "\n",
    "# # Drop original categorical columns and concatenate the new encoded DataFrame\n",
    "# X = X.drop(categorical_columns, axis=1)\n",
    "# X = pd.concat([X, X_encoded], axis=1)\n",
    "    \n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52500, 11), (17500, 11))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 128)               12928     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42340 (165.39 KB)\n",
      "Trainable params: 42340 (165.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 128)               12928     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29569 (115.50 KB)\n",
      "Trainable params: 29569 (115.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# This script defines the generator and discriminator models for a Generative Adversarial Imputation Network (GAIN)\n",
    "# using the Keras API in TensorFlow 2.x.\n",
    "\n",
    "def build_generator(data_dim, hidden_dim):\n",
    "    \"\"\"\n",
    "    Builds the generator model for a Generative Adversarial Imputation Network (GAIN).\n",
    "\n",
    "    Args:\n",
    "        data_dim (int): The dimensionality of the input data.\n",
    "        hidden_dim (int): The number of hidden units in the encoder and decoder.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The generator model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(data_dim,)),  # Input layer\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),  # Hidden layers\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(data_dim, activation='sigmoid')  # Output layer\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(data_dim, hidden_dim):\n",
    "    \"\"\"\n",
    "    Builds the discriminator model for a Generative Adversarial Imputation Network (GAIN).\n",
    "\n",
    "    Args:\n",
    "        data_dim (int): The dimensionality of the input data.\n",
    "        hidden_dim (int): The number of hidden units in the encoder and decoder.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The discriminator model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(data_dim,)),  # Input layer\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),  # Hidden layers\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Example model structures\n",
    "generator_example = build_generator(data_dim=100, hidden_dim=128)\n",
    "discriminator_example = build_discriminator(data_dim=100, hidden_dim=128)\n",
    "\n",
    "# Print the model summary\n",
    "generator_example.summary(), discriminator_example.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a loss function that measures the difference between the predicted output and the ground truth output in a binary classification problem\n",
    "# In the context of GANs, we use it to measure the difference between the real and fake outputs of the discriminator\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    \"\"\"\n",
    "    Compute the discriminator loss given real and fake outputs.\n",
    "    \n",
    "    Args:\n",
    "        real_output (tf.Tensor): Real outputs from the discriminator.\n",
    "        fake_output (tf.Tensor): Fake outputs from the discriminator.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Total loss of the discriminator.\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    \"\"\"\n",
    "    Compute the generator loss given fake outputs.\n",
    "    \n",
    "    Args:\n",
    "        fake_output (tf.Tensor): Fake outputs from the generator.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Loss of the generator.\n",
    "    \"\"\"\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# Adam optimizer is a stochastic gradient descent method\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(generator, discriminator, data, batch_size):\n",
    "    \"\"\"\n",
    "    Performs a single step of training in a GAN model.\n",
    "\n",
    "    Args:\n",
    "        generator: The generator model.\n",
    "        discriminator: The discriminator model.\n",
    "        data: The data batch.\n",
    "        batch_size: The size of the batch.\n",
    "\n",
    "    Returns:\n",
    "        The generator and discriminator losses.\n",
    "    \"\"\"\n",
    "    # Generate noise for the batch size\n",
    "    noise = tf.random.normal([batch_size, data.shape[1]])\n",
    "\n",
    "    # Perform gradient tape\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generate data using the generator\n",
    "        generated_data = generator(noise, training=True)\n",
    "\n",
    "        # Get the real and fake outputs for the discriminator\n",
    "        real_output = discriminator(data, training=True)\n",
    "        fake_output = discriminator(generated_data, training=True)\n",
    "\n",
    "        # Calculate the generator and discriminator losses\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    # Calculate the gradients of the generator and discriminator\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Apply the gradients to update the models\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Return the losses\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "\n",
    "def train_gan(generator, discriminator, df, iterations, batch_size):\n",
    "    \"\"\"\n",
    "    Trains a GAN model.\n",
    "\n",
    "    Args:\n",
    "        generator: The generator model.\n",
    "        discriminator: The discriminator model.\n",
    "        df: The data frame.\n",
    "        iterations: The number of training iterations.\n",
    "        batch_size: The size of the batch.\n",
    "    \"\"\"\n",
    "    for iteration in range(iterations):\n",
    "        # Sample data from the dataframe\n",
    "        idx = np.random.choice(len(df), batch_size, replace=False)\n",
    "        data_batch = df.iloc[idx]\n",
    "\n",
    "        # Perform a training step\n",
    "        gen_loss, disc_loss = train_step(generator, discriminator, data_batch, batch_size)\n",
    "\n",
    "        # Print the losses every 1000 iterations\n",
    "        if iteration % 1000 == 0:\n",
    "            print(f\"Iteration {iteration}, Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Generator Loss: 0.7769594788551331, Discriminator Loss: 1.424678087234497\n",
      "Iteration 1000, Generator Loss: 1.4149186611175537, Discriminator Loss: 0.5913563370704651\n",
      "Iteration 2000, Generator Loss: 1.5766181945800781, Discriminator Loss: 0.5552126169204712\n",
      "Iteration 3000, Generator Loss: 1.132271647453308, Discriminator Loss: 0.9842506647109985\n",
      "Iteration 4000, Generator Loss: 1.9426381587982178, Discriminator Loss: 0.44074156880378723\n",
      "Iteration 5000, Generator Loss: 1.3435235023498535, Discriminator Loss: 0.811878502368927\n",
      "Iteration 6000, Generator Loss: 1.201859712600708, Discriminator Loss: 0.8797151446342468\n",
      "Iteration 7000, Generator Loss: 1.205348253250122, Discriminator Loss: 0.8930308818817139\n",
      "Iteration 8000, Generator Loss: 1.3386163711547852, Discriminator Loss: 0.8799046277999878\n",
      "Iteration 9000, Generator Loss: 1.2355411052703857, Discriminator Loss: 0.8162071108818054\n"
     ]
    }
   ],
   "source": [
    "# Setup models\n",
    "data_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "\n",
    "generator = build_generator(data_dim, hidden_dim)\n",
    "discriminator = build_discriminator(data_dim, hidden_dim)\n",
    "\n",
    "# Start training\n",
    "train_gan(generator, discriminator, X_train, iterations=10000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardio_gain_generator.h5']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(generator, 'cardio_gain_generator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
