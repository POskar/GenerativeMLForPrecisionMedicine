{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_STATE = 404"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/cardio_train.csv', delimiter=';')\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['cardio'])\n",
    "y = df['cardio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.436062</td>\n",
       "      <td>2</td>\n",
       "      <td>0.443452</td>\n",
       "      <td>-0.847873</td>\n",
       "      <td>-0.122182</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307686</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.018168</td>\n",
       "      <td>0.749831</td>\n",
       "      <td>0.072610</td>\n",
       "      <td>-0.035180</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.247997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078047</td>\n",
       "      <td>-0.708942</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>-0.141297</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.748152</td>\n",
       "      <td>2</td>\n",
       "      <td>0.565254</td>\n",
       "      <td>0.541435</td>\n",
       "      <td>0.137541</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.808543</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.018168</td>\n",
       "      <td>-1.264666</td>\n",
       "      <td>-0.187113</td>\n",
       "      <td>-0.194356</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender    height    weight     ap_hi     ap_lo  cholesterol  \\\n",
       "0 -0.436062       2  0.443452 -0.847873 -0.122182 -0.088238            1   \n",
       "1  0.307686       1 -1.018168  0.749831  0.072610 -0.035180            3   \n",
       "2 -0.247997       1  0.078047 -0.708942  0.007679 -0.141297            3   \n",
       "3 -0.748152       2  0.565254  0.541435  0.137541  0.017879            1   \n",
       "4 -0.808543       1 -1.018168 -1.264666 -0.187113 -0.194356            1   \n",
       "\n",
       "   gluc  smoke  alco  active  \n",
       "0     1      0     0       1  \n",
       "1     1      0     0       1  \n",
       "2     1      0     0       0  \n",
       "3     1      0     0       1  \n",
       "4     1      0     0       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Select columns to be scaled\n",
    "numeric_columns = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "categorical_columns = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "# Fit and transform your data (only for numeric columns)\n",
    "scaler = StandardScaler()\n",
    "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "# # Apply one-hot encoding to categorical columns\n",
    "# encoder = OneHotEncoder(sparse_output=False)  # Create the encoder\n",
    "# X_encoded = encoder.fit_transform(X[categorical_columns])  # Fit and transform the categorical data\n",
    "# column_names = encoder.get_feature_names_out(categorical_columns)  # Get new column names for encoded features\n",
    "# X_encoded = pd.DataFrame(X_encoded, columns=column_names)  # Create a DataFrame with the new column names\n",
    "\n",
    "# # Drop original categorical columns and concatenate the new encoded DataFrame\n",
    "# X = X.drop(categorical_columns, axis=1)\n",
    "# X = pd.concat([X, X_encoded], axis=1)\n",
    "    \n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52500, 11), (17500, 11))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pieni\\Documents\\GitHub\\GenerativeMLForPrecisionMedicine\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\pieni\\Documents\\GitHub\\GenerativeMLForPrecisionMedicine\\.venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               12928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42340 (165.39 KB)\n",
      "Trainable params: 42340 (165.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               12928     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29569 (115.50 KB)\n",
      "Trainable params: 29569 (115.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# This script defines the generator and discriminator models for a Generative Adversarial Imputation Network (GAIN)\n",
    "# using the Keras API in TensorFlow 2.x.\n",
    "\n",
    "def build_generator(data_dim, hidden_dim):\n",
    "    \"\"\"\n",
    "    Builds the generator model for a Generative Adversarial Imputation Network (GAIN).\n",
    "\n",
    "    Args:\n",
    "        data_dim (int): The dimensionality of the input data.\n",
    "        hidden_dim (int): The number of hidden units in the encoder and decoder.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The generator model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(data_dim,)),  # Input layer\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),  # Hidden layers\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(data_dim, activation='sigmoid')  # Output layer\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(data_dim, hidden_dim):\n",
    "    \"\"\"\n",
    "    Builds the discriminator model for a Generative Adversarial Imputation Network (GAIN).\n",
    "\n",
    "    Args:\n",
    "        data_dim (int): The dimensionality of the input data.\n",
    "        hidden_dim (int): The number of hidden units in the encoder and decoder.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The discriminator model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(data_dim,)),  # Input layer\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),  # Hidden layers\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Example model structures\n",
    "generator_example = build_generator(data_dim=100, hidden_dim=128)\n",
    "discriminator_example = build_discriminator(data_dim=100, hidden_dim=128)\n",
    "\n",
    "# Print the model summary\n",
    "generator_example.summary(), discriminator_example.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a loss function that measures the difference between the predicted output and the ground truth output in a binary classification problem\n",
    "# In the context of GANs, we use it to measure the difference between the real and fake outputs of the discriminator\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    \"\"\"\n",
    "    Compute the discriminator loss given real and fake outputs.\n",
    "    \n",
    "    Args:\n",
    "        real_output (tf.Tensor): Real outputs from the discriminator.\n",
    "        fake_output (tf.Tensor): Fake outputs from the discriminator.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Total loss of the discriminator.\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    \"\"\"\n",
    "    Compute the generator loss given fake outputs.\n",
    "    \n",
    "    Args:\n",
    "        fake_output (tf.Tensor): Fake outputs from the generator.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Loss of the generator.\n",
    "    \"\"\"\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# Adam optimizer is a stochastic gradient descent method\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(generator, discriminator, data, batch_size):\n",
    "    \"\"\"\n",
    "    Performs a single step of training in a GAN model.\n",
    "\n",
    "    Args:\n",
    "        generator: The generator model.\n",
    "        discriminator: The discriminator model.\n",
    "        data: The data batch.\n",
    "        batch_size: The size of the batch.\n",
    "\n",
    "    Returns:\n",
    "        The generator and discriminator losses.\n",
    "    \"\"\"\n",
    "    # Generate noise for the batch size\n",
    "    noise = tf.random.normal([batch_size, data.shape[1]])\n",
    "\n",
    "    # Perform gradient tape\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generate data using the generator\n",
    "        generated_data = generator(noise, training=True)\n",
    "\n",
    "        # Get the real and fake outputs for the discriminator\n",
    "        real_output = discriminator(data, training=True)\n",
    "        fake_output = discriminator(generated_data, training=True)\n",
    "\n",
    "        # Calculate the generator and discriminator losses\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    # Calculate the gradients of the generator and discriminator\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Apply the gradients to update the models\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Return the losses\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "\n",
    "def train_gan(generator, discriminator, df, iterations, batch_size):\n",
    "    \"\"\"\n",
    "    Trains a GAN model.\n",
    "\n",
    "    Args:\n",
    "        generator: The generator model.\n",
    "        discriminator: The discriminator model.\n",
    "        df: The data frame.\n",
    "        iterations: The number of training iterations.\n",
    "        batch_size: The size of the batch.\n",
    "    \"\"\"\n",
    "    for iteration in range(iterations):\n",
    "        # Sample data from the dataframe\n",
    "        idx = np.random.choice(len(df), batch_size, replace=False)\n",
    "        data_batch = df.iloc[idx]\n",
    "\n",
    "        # Perform a training step\n",
    "        gen_loss, disc_loss = train_step(generator, discriminator, data_batch, batch_size)\n",
    "\n",
    "        # Print the losses every 1000 iterations\n",
    "        if iteration % 1000 == 0:\n",
    "            print(f\"Iteration {iteration}, Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Generator Loss: 0.596081018447876, Discriminator Loss: 1.4378794431686401\n",
      "Iteration 1000, Generator Loss: 0.9769333004951477, Discriminator Loss: 0.7703642845153809\n",
      "Iteration 2000, Generator Loss: 4.705746650695801, Discriminator Loss: 0.012789323925971985\n",
      "Iteration 3000, Generator Loss: 3.0111231803894043, Discriminator Loss: 0.15267401933670044\n",
      "Iteration 4000, Generator Loss: 4.889562606811523, Discriminator Loss: 0.03696933016180992\n",
      "Iteration 5000, Generator Loss: 5.278817176818848, Discriminator Loss: 0.012114879675209522\n",
      "Iteration 6000, Generator Loss: 5.800377368927002, Discriminator Loss: 0.0038595963269472122\n",
      "Iteration 7000, Generator Loss: 4.971675395965576, Discriminator Loss: 0.007355513516813517\n",
      "Iteration 8000, Generator Loss: 7.258411884307861, Discriminator Loss: 0.18951641023159027\n",
      "Iteration 9000, Generator Loss: 5.718896865844727, Discriminator Loss: 0.006278046406805515\n"
     ]
    }
   ],
   "source": [
    "# Setup models\n",
    "data_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "\n",
    "generator = build_generator(data_dim, hidden_dim)\n",
    "discriminator = build_discriminator(data_dim, hidden_dim)\n",
    "\n",
    "# Start training\n",
    "train_gan(generator, discriminator, X_train, iterations=10000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardio_gain_generator.h5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(generator, 'cardio_gain_generator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
